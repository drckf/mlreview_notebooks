{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCPB 20-21 exercise 2\n",
    "\n",
    "### Saverio Monaco\n",
    "\n",
    "### Gerardo Carmona\n",
    "\n",
    "### Hilario Capettini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adadelta, Adagrad, Adam, Adamax, RMSprop, SGD\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"DATA/sequences16.csv\"\n",
    "sx, sy = np.loadtxt(fname,delimiter=',',\n",
    "                   usecols=(0,1), unpack=True, dtype=str)\n",
    "N = len(sy)\n",
    "\n",
    "Ls = len(sx[0])\n",
    "\n",
    "\n",
    "perc_train = 0.8 # I kept the same train-test ratio as in the lesson\n",
    "N_train = int(N*perc_train)\n",
    "N_test = N - N_train\n",
    "\n",
    "print('Size of the sequences:   ',Ls)\n",
    "print('Size of the data:        ',N)\n",
    "print('Size of the training set:',N_train)\n",
    "print('Size of the test set:    ',N_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just printing some datas to check it\n",
    "# I noticed this isn't the same rule in the lessons, so it is unkown\n",
    "for _ in range(10):\n",
    "    print(sx[_],sy[_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting the label set to int values:\n",
    "print(sy[0],type(sy[0]))\n",
    "y = sy.astype(int)\n",
    "print(y[0],type(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letters and number of letters\n",
    "Q = ['A', 'C', 'G', 'T']\n",
    "Nc = 4\n",
    "\n",
    "# building the dictionary\n",
    "onehc = {Q[i]: i for i in range (Nc)}\n",
    "\n",
    "L = Ls * Nc # lenght of the input array (64)\n",
    "\n",
    "# The following cycle will transform the input vectors (for ex.: AAGGTCTGCCGGCCGA) in a\n",
    "# binary like way\n",
    "#\n",
    "# A = 1000\n",
    "# C = 0100\n",
    "# G = 0010\n",
    "# T = 0001\n",
    "#\n",
    "#   A    A    G    G    T    C   ...\n",
    "# 1000 1000 0010 0010 0001 0100\n",
    "x = np.zeros((N,L))\n",
    "for n in range(N): #for all the samples\n",
    "    for i in range(Ls): # for every character\n",
    "        x[n][i*4 + onehc[sx[n][i]]] = 1\n",
    "        \n",
    "print(sx[0])\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = (x[:N_train],y[:N_train])\n",
    "(x_test, y_test) = (x[N_train:],y[N_train:])\n",
    "\n",
    "# Check the fraction of datas equal to one\n",
    "print(y_train.sum() / N_train)\n",
    "print(y_test.sum() / N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is the model converging with a smaller database of samples with longer sequences? By converging we mean reducing significantly the validation loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I MADE THE SAME TRAINING IMPLEMENTING 3 FUNCTIONS\n",
    "# layer_i is an array representing a hidden layer used to create a neural network:\n",
    "# layer_i = [nodes, activation, dropout_ratio]\n",
    "# hidden_layers is a array of the hidden layers\n",
    "layer_1 = [L/2, 'relu', 0]\n",
    "layer_2 = [L/4, 'relu', .2]\n",
    "hidden_layers = [layer_1,layer_2]\n",
    "\n",
    "# optimization chosen\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9, nesterov= True)\n",
    "\n",
    "# the first function creates the Neural Network, it needs the input dimension and the array of layers\n",
    "def createmodel(input_dim, hid_layers,activation = None, dropout = None, summary = False):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # we add the first layer (input layer)\n",
    "    model.add(Dense(input_dim, input_shape=(input_dim,)))\n",
    "    \n",
    "    # we add the hidden layers\n",
    "    for layer in hid_layers:\n",
    "        act = activation or layer[1]\n",
    "        model.add(Dense(layer[0],activation=act))\n",
    "        drop = dropout or layer[2]\n",
    "        if drop: model.add(Dropout(drop))\n",
    "    \n",
    "    # we add the output layer\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    if summary: print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# the second function trains the model created with createmodel, as a input it needs the output of createmodels\n",
    "# the optimization and the arguments of model.fit() (except for shuffle)\n",
    "def trainmodel(model, opt, *args, verbose = 0, **kwargs):\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    fit = model.fit(*args, **kwargs, shuffle = True, verbose = verbose)\n",
    "    '''fit = model.fit(x_train, y_train,\n",
    "                    epochs = 60, batch_size = 50,\n",
    "                    validation_data = (x_test,y_test),\n",
    "                    shuffle = True)'''\n",
    "    \n",
    "    return fit\n",
    "\n",
    "# the third function takes the output of trainmodel and plot the loss of training data and test data\n",
    "def plotmodel(fit):\n",
    "    for obs in ('accuracy', 'loss'):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(fit.history[obs], 'r', label = obs + ' of training data')\n",
    "        plt.plot(fit.history['val_'+obs], 'b--', label = obs + ' of test data')\n",
    "        plt.ylabel(obs)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the model\n",
    "model = createmodel(L,hidden_layers, summary = True)\n",
    "\n",
    "#Train the NN\n",
    "training = trainmodel(model, opt, x_train, y_train,\n",
    "          epochs=60, batch_size=50, validation_data= (x_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "plotmodel(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the loss function is not converging over the test samples for this set of longer strings (16 characters) and less samples (3000) when compared with the dataset studied during the third lecture. On the other hand the loss function over the test set was converging for the case of the aforementioned dataset, reaching an approximate value of 0.2.\n",
    "\n",
    "This is something reasonable since the number of trainable parameters for the NN (6785) is bigger than the number of samples in the dataset (3000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Try to improve the performance of the DNN over the validation data set by “augmenting”\n",
    "the training data: For every sample there are L s -1 periodic shifts of the kind\n",
    "AAACCCTTTGGG→ GAAACCCTTTGG → GGAAACCCTTTG→ etc.\n",
    "We know that they can break the keys and provide a sample x’[n] with wrong label y[n]\n",
    "(which is the label of original sample x[n]), but they also enlarge the number of good\n",
    "samples for the DNN. Which of the two effects is prevalent?\n",
    "Is the situation improving by augmenting the training data from N t real samples to L s *N t ones with this procedure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function produces the permutations\n",
    "rot = lambda A: [A[i:]+A[:i] for i in range(len(A))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate the augmented data\n",
    "sxx = []\n",
    "syy = np.zeros(len(sx)*Ls)\n",
    "for i in range(len(sx)):\n",
    "    sxx= np.append(sxx,rot(sx[i]))\n",
    "    syy[i*Ls:(i+1)*Ls] = sy[i]\n",
    "syy = syy.astype(int)\n",
    "\n",
    "#Now we permutate the samples \n",
    "permutation = np.random.permutation(sxx.shape[0])\n",
    "\n",
    "sxx = sxx[permutation] \n",
    "syy = syy[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(syy)\n",
    "\n",
    "Ls = len(sxx[0])\n",
    "\n",
    "perc_train = 0.8 # I kept the same train-test ratio as in the lesson\n",
    "N_train = int(N*perc_train)\n",
    "N_test = N - N_train\n",
    "\n",
    "print('Size of the sequences:   ',Ls)\n",
    "print('Size of the data:        ',N)\n",
    "print('Size of the training set:',N_train)\n",
    "print('Size of the test set:    ',N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = syy\n",
    "x = np.zeros((N,L))\n",
    "for n in range(N): #for all the samples\n",
    "    for i in range(Ls): # for every character\n",
    "        x[n][i*4 + onehc[sxx[n][i]]] = 1\n",
    "        \n",
    "print(sxx[0])\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = (x[:N_train],y[:N_train])\n",
    "(x_test, y_test) = (x[N_train:],y[N_train:])\n",
    "\n",
    "# Check the fraction of datas equal to one\n",
    "print(y_train.sum() / N_train)\n",
    "print(y_test.sum() / N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the model\n",
    "model = createmodel(L,hidden_layers, summary = True)\n",
    "\n",
    "#Train the NN\n",
    "training = trainmodel(model, opt, x_train, y_train,\n",
    "          epochs=60, batch_size=50, validation_data= (x_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "plotmodel(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the training of the NN over the augmented data is highly effective for this case. The accuracy over the test data is converging above 0.9 while the loss over the same dataset is converging to a value below 0.25. When those plots are compared with the previous where the dataset was 16 times smaller we can say that the procedure for augmenting the data has been successful. Even when we are introducing false positives inside of the dataset.\n",
    "\n",
    "Clearly the prevalent effect is that more real samples are being produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement a “grid search” as shown in NB11 to improve one or more of the aspects or\n",
    "parameters of the model. Possible tests include: different activation units (sigmoid, relu, elu,\n",
    "etc.), different minimization algorithms (ADAM, RMSprop, Nesterov, etc.), different\n",
    "dropouts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(optimizer, activation = None, dropout = None, learning_rate = 0.1):\n",
    "    model = createmodel(L,hidden_layers, activation = activation, dropout = dropout)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer(learning_rate = learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Using Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn=compile_model, \n",
    "                        epochs=60,\n",
    "                        batch_size = 50, \n",
    "                        verbose=1)\n",
    "\n",
    "optimizer = [SGD, RMSprop, Adam, Adamax]\n",
    "dropout = [0.1,0.3,0.5]\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "activation = ['relu', 'elu']\n",
    "\n",
    "# parameters dictionary\n",
    "param_grid = dict(optimizer=optimizer, activation = activation, dropout = dropout, learning_rate = learning_rate)\n",
    "# Run gridsearch\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=-1, cv=4)\n",
    "grid_result = grid.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "best_score = grid_result.best_score_\n",
    "best_params = grid_result.best_params_\n",
    "best_activation, best_dropout, best_lr, best_opt = best_params['activation'], best_params['dropout'], best_params['learning_rate'], best_params['optimizer']\n",
    "print(f\"Best: {best_score} using {best_params}\")\n",
    "\n",
    "\n",
    "print(\"All mean scores on the grid:\")\n",
    "allscores =grid_result.cv_results_['mean_test_score']\n",
    "stdscores =grid_result.cv_results_['std_test_score']\n",
    "print('%-25s%-15s%-15s%-22s%-20s%-25s' %('Optimizer','Activation','Dropout','Learning rate','Score','Mean time'))\n",
    "print('------------------------------------------------------------------------------------------------------------')\n",
    "scores =[]\n",
    "for i in range(len(allscores)):\n",
    "    print('%-27s %-13s %-18.1f %-10.3f %-6.3f %-3s %-6.3f  ' %(str(grid_result.cv_results_['params'][i]['optimizer'])[42:][:-2],\n",
    "                                               grid_result.cv_results_['params'][i]['activation'],\n",
    "                                               grid_result.cv_results_['params'][i]['dropout'],\n",
    "                                               grid_result.cv_results_['params'][i]['learning_rate'],\n",
    "                                               allscores[i],'+/-',stdscores[i]),\n",
    "                                               grid_result.cv_results_['mean_fit_time'][i])\n",
    "    scores.append(allscores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled histogram\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.scatter(np.linspace(1,len(allscores),num=len(allscores)),scores)\n",
    "\n",
    "plt.title('Scores for the different configurations', fontsize=20)\n",
    "plt.xlabel('Implemented models', fontsize=20)\n",
    "plt.ylabel('Scores', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. See if any rescaling of data may improve the results. For instance one may use [-0.5,+0.5]\n",
    "instead of [0,1] for every bit of x[n]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_input(x, shift, largeness):\n",
    "    return (x - .5 )* largeness + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally as a preprocessing operation the data is rescaled, here we see the importance of this preprocessing\n",
    "# operation.\n",
    "# First we center our data around zero:\n",
    "#          [0,1] --> [-1.5,1.5]\n",
    "\n",
    "# Rescaling transformation\n",
    "resc_x = rescale_input(x,0,3)\n",
    "\n",
    "# y remains the same\n",
    "resc_y = (y)\n",
    "\n",
    "# print the inputs just as a check\n",
    "print(resc_x)\n",
    "\n",
    "(resc_x_train, resc_y_train) = (resc_x[:N_train],resc_y[:N_train])\n",
    "(resc_x_test, resc_y_test) = (resc_x[N_train:],resc_y[N_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = createmodel(L, hidden_layers, activation= best_activation, dropout= best_dropout)\n",
    "best_opt = best_opt(learning_rate=best_lr)\n",
    "# Training of the model with the rescaled data\n",
    "resc_training = trainmodel(best_model, best_opt, resc_x_train, resc_y_train,\n",
    "          epochs=60, batch_size=50, validation_data= (resc_x_test, resc_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "resc_score = best_model.evaluate(resc_x_test, resc_y_test, verbose=1)\n",
    "\n",
    "plotmodel(resc_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:                  ', round(score[0],5))\n",
    "print('Rescaled Data Test loss:    ', round(resc_score[0],5))\n",
    "\n",
    "print('\\nTest accuracy:              ', round(score[1],5))\n",
    "print('Rescaled Data Test accuracy:', round(resc_score[1],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we rescale the data to be far away from zero, we should expect less quality of the training due to \n",
    "# Gradient Vanishing\n",
    "# Rescaling transformation\n",
    "resc_x_2 = rescale_input(x,10,3)\n",
    "\n",
    "# y remains the same\n",
    "resc_y_2 = (y)\n",
    "\n",
    "# print the inputs just as a check\n",
    "print(resc_x_2)\n",
    "\n",
    "(resc_x_2_train, resc_y_2_train) = (resc_x_2[:N_train],resc_y_2[:N_train])\n",
    "(resc_x_2_test, resc_y_2_test) = (resc_x_2[N_train:],resc_y_2[N_train:])\n",
    "\n",
    "# Reinitialize the model\n",
    "best_model = createmodel(L, hidden_layers, activation= best_activation, dropout= best_dropout)\n",
    "\n",
    "# Training of the model with the rescaled data\n",
    "resc_2_training = trainmodel(best_model, best_opt, resc_x_2_train, resc_y_2_train,\n",
    "          epochs=60, batch_size=50, validation_data= (resc_x_2_test, resc_y_2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resc_2_score = best_model.evaluate(resc_x_2_test, resc_y_2_test, verbose=1)\n",
    "\n",
    "plotmodel(resc_2_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:                  ', round(score[0],5))\n",
    "print('Rescaled Data Test loss:    ', round(resc_2_score[0],5))\n",
    "\n",
    "print('\\nTest accuracy:              ', round(score[1],5))\n",
    "print('Rescaled Data Test accuracy:', round(resc_2_score[1],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
