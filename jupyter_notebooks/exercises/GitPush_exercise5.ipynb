{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sgm = lambda x: 1/(1+np.exp(-x))\n",
    "nrand = np.random.random\n",
    "zerov = np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    '''A restricted Boltzmann machine model.'''\n",
    "    def __init__(self, n_variables, n_hidden, spin = False):\n",
    "        sigma = np.sqrt(4./(n_hidden+n_variables))\n",
    "        self.a = sigma*(2*nrand(n_variables)-1)\n",
    "        self.b = zerov(n_hidden)\n",
    "        self.w = sigma*(2*nrand((n_variables,n_hidden))-1)\n",
    "        self.min = -1*spin # Evaluates to zero if the model is not spin-based\n",
    "\n",
    "    def activate(self, v, w, b, gap = 1):\n",
    "        '''Turns the neurons of a forward layer on, according to a sigmoid probability function.'''\n",
    "        vec = v@w + b # The neurons evaluation\n",
    "        l = len(vec) # sample size\n",
    "        prob = sgm(gap*vec)\n",
    "        out = np.full(prob.shape,self.min)\n",
    "        out[prob < nrand(prob.shape)] = 1\n",
    "        return out\n",
    "    \n",
    "    def sample(self, v_data, steps = 1):\n",
    "        h_data = self.activate(v_data, self.w, self.b)\n",
    "        h_model = h_data\n",
    "        for _ in range(steps):\n",
    "            v_model = self.activate(h_model, self.w.T, self.a)\n",
    "            h_model = self.activate(v_model, self.w, self.b)\n",
    "        return h_data, v_model, h_model\n",
    "    \n",
    "    def grad(self, v_data, h_data, v_model, h_model):\n",
    "        da = np.average(v_data - v_model, axis = 0)\n",
    "        db = np.average(h_data - h_model, axis = 0)\n",
    "        dw = sum(np.outer(v_data[i].T,h_data[i])-np.outer(v_model[i].T,h_model[i]) for i in range(len(v_data)))/len(v_data)\n",
    "        #np.average(np.outer(v_data,h_data)-np.outer(v_model,h_model), axis = 1)\n",
    "        return da, db, dw\n",
    "\n",
    "    def train(self, data, n_epochs = 10, batch_size = 30, learning_rate = 1):\n",
    "        batches = len(data)//batch_size\n",
    "        n_variables = len(self.a)\n",
    "        n_hidden = len(self.b)\n",
    "        for epoch in range(n_epochs):\n",
    "            np.random.shuffle(data)\n",
    "            for i in range(batches):\n",
    "                #v = data[i*batch_size:(i+1)*batch_size]\n",
    "                #h, v_m, h_m = self.sample(v)\n",
    "                #ca, cb, cw = self.grad(v,h,v_m,h_m)\n",
    "                #self.a += learning_rate*ca\n",
    "                #self.b += learning_rate*cb\n",
    "                #self.w += learning_rate*cw\n",
    "                for j, v in enumerate(data[i*batch_size:(i+1)*batch_size]):\n",
    "                    if j%batch_size == 0:\n",
    "                        v_data, v_model = np.zeros(n_variables), np.zeros(n_variables)\n",
    "                        h_data, h_model = np.zeros(n_hidden), np.zeros(n_hidden)\n",
    "                        vh_data, vh_model = np.zeros((n_variables, n_hidden)), np.zeros((n_variables, n_hidden))\n",
    "                    h, v_m, h_m = self.sample(v)\n",
    "                    v_data += v\n",
    "                    h_data += h\n",
    "                    v_model += v_m\n",
    "                    h_model += h_m\n",
    "                    vh_data += np.outer(v.T,h)\n",
    "                    vh_model += np.outer(v_m.T,h_m)\n",
    "                    if j%batch_size == batch_size - 1:\n",
    "                        C = learning_rate / batch_size\n",
    "                        dw = C*(vh_data - vh_model)\n",
    "                        da = C*(v_data - v_model)\n",
    "                        db = C*(h_data - h_model)\n",
    "                        self.w += dw\n",
    "                        self.a += da\n",
    "                        self.b += db\n",
    "\n",
    "            learning_rate = learning_rate/(0.05*learning_rate+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-1887cda36eef>:2: RuntimeWarning: overflow encountered in exp\n  sgm = lambda x: 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('DATA/dataRBM_q0.1.csv', delimiter = ',')\n",
    "rbm = RBM(len(data[0]),3)\n",
    "rbm.train(data, n_epochs = 30, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-1887cda36eef>:2: RuntimeWarning: overflow encountered in exp\n  sgm = lambda x: 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "_, v_fantasy, h_fantasy = rbm.sample(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 1, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "v_fantasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38564bit075de96200f448aeb6d0298b6117be4d",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}