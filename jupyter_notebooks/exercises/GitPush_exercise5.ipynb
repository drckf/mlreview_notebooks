{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sgm = lambda x: 1/(1+np.exp(-x))\n",
    "nrand = np.random.random\n",
    "zerov = np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    '''A restricted Boltzmann machine model.'''\n",
    "    def __init__(self, n_variables, n_hidden, spin = False):\n",
    "        sigma = np.sqrt(4./(n_hidden+n_variables))\n",
    "        self.a = sigma*(2*nrand(n_variables)-1)\n",
    "        self.b = zerov(n_hidden)\n",
    "        self.w = sigma*(2*nrand((n_variables,n_hidden))-1)\n",
    "        self.min = -1*spin # Evaluates to zero if the model is not spin-based\n",
    "        self.gap = 1 + spin # Evaluates to two if the model is spin-based\n",
    "\n",
    "    def activate(self, v, w, b, beta):\n",
    "        '''Turns the neurons of a forward layer on, according to a sigmoid probability function.'''\n",
    "        vec = v@w + b # The neurons evaluation\n",
    "        l = len(vec) # sample size\n",
    "        prob = sgm(beta*vec)\n",
    "        out = np.full(prob.shape,self.min)\n",
    "        out[nrand(prob.shape) < prob] = 1\n",
    "        return out\n",
    "    \n",
    "    def sample(self, v_data, steps = 1):\n",
    "        h_data = self.activate(v_data, self.w, self.b, self.gap)\n",
    "        h_model = h_data\n",
    "        for _ in range(steps):\n",
    "            v_model = self.activate(h_model, self.w.T, self.a, self.gap)\n",
    "            h_model = self.activate(v_model, self.w, self.b, self.gap)\n",
    "        return h_data, v_model, h_model\n",
    "    \n",
    "    def grad(self, v_data, h_data, v_model, h_model):\n",
    "        da = np.average(v_data - v_model, axis = 0)\n",
    "        db = np.average(h_data - h_model, axis = 0)\n",
    "        dw = sum(np.outer(v_data[i].T,h_data[i])-np.outer(v_model[i].T,h_model[i]) for i in range(len(v_data)))/len(v_data)\n",
    "        #np.average(np.outer(v_data,h_data)-np.outer(v_model,h_model), axis = 1)\n",
    "        return da, db, dw\n",
    "    \n",
    "    '''PLOTTING PURPOSES'''\n",
    "    # This function set the coordinates (dots) for the unit of the visible layers and\n",
    "    # the one in the hidden layer in the plot\n",
    "    def create_coord(self,np,x0):\n",
    "        x = [x0] * np\n",
    "        y = list(range(np)) # weird way to spell np.arange(0,10)\n",
    "        for i in range(np):\n",
    "            y[i] = y[i]/(np-1.) - 0.5\n",
    "        return (x,y)\n",
    "    \n",
    "    '''PLOTTING PURPOSES'''\n",
    "    def mycolor(self,val):\n",
    "        if val > 0:\n",
    "            return \"red\"\n",
    "        elif val < 0:\n",
    "            return \"blue\"\n",
    "        return \"black\"\n",
    "    \n",
    "    '''PLOTTING PURPOSES'''\n",
    "    # This makes actually the plot, it display all the units and all the weight with a\n",
    "    # color and an intensity (the thickness)\n",
    "    def plotgraph(self,epoch=0,):\n",
    "        (x1,y1) = self.create_coord(len(self.a),0)\n",
    "        (x2,y2) = self.create_coord(len(self.b),1)\n",
    "\n",
    "        A = 2./self.w.max()\n",
    "        for i in range(len(self.a)): # L are visible (LEFT)\n",
    "            for j in range(len(self.b)): # M are hidden (RIGHT)\n",
    "                ex, ey, col = (x1[i],x2[j]), (y1[i],y2[j]), self.mycolor(self.w[i][j])\n",
    "                plt.plot(ex,ey,col,zorder=1, lw=A*np.abs(self.w[i][j]))\n",
    "        A = 300. /(self.a.max()+self.b.max())\n",
    "\n",
    "        # Left dots\n",
    "        for i in range(len(self.a)):\n",
    "            plt.scatter(x1[i],y1[i],s=A*np.abs(self.a[i]),zorder=2,c=self.mycolor(self.a[i]))\n",
    "        \n",
    "        # Right dots\n",
    "        for j in range(len(self.b)):\n",
    "            plt.scatter(x2[j],y2[j],s=A*np.abs(self.b[j]),zorder=2,c=self.mycolor(self.b[j]))\n",
    "        \n",
    "        plt.title(f\">0 red, <0 blue, epoch={epoch}\")\n",
    "        plt.show()\n",
    "        \n",
    "    def train(self, data, n_epochs = 10, batch_size = 30, learning_rate = 1, nplot = 0, meansq = False):\n",
    "        batches = len(data)//batch_size\n",
    "        n_variables = len(self.a)\n",
    "        n_hidden = len(self.b)\n",
    "        \n",
    "        if meansq:\n",
    "            meansqovertime = []\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            np.random.shuffle(data)\n",
    "            \n",
    "            if meansq:\n",
    "                dw = 0\n",
    "            \n",
    "            for i in range(batches):\n",
    "                v = data[i*batch_size:(i+1)*batch_size]\n",
    "                h, v_m, h_m = self.sample(v)\n",
    "                ca, cb, cw = self.grad(v,h,v_m,h_m)\n",
    "                self.a += learning_rate*ca\n",
    "                self.b += learning_rate*cb\n",
    "                self.w += learning_rate*cw\n",
    "                if meansq:\n",
    "                    dw += learning_rate*cw\n",
    "            if meansq:\n",
    "                meansqovertime.append(np.mean(np.square(np.asarray(dw))))\n",
    "            learning_rate = learning_rate/(0.05*learning_rate+1)\n",
    "            # I just want to plot nplot times (NOT TOTALLY CORRECT, just a detail though)\n",
    "            if nplot:\n",
    "                if (epoch)%(int(n_epochs/nplot)) == 0:\n",
    "                    self.plotgraph(epoch)\n",
    "                    print(\"l_rate=\",learning_rate)\n",
    "        if nplot:\n",
    "            self.plotgraph(epoch)\n",
    "            print(\"l_rate=\",learning_rate)\n",
    "        \n",
    "        if meansq:\n",
    "            t = np.arange(len(meansqovertime))\n",
    "            plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "            plt.title('Mean square increment of weights')\n",
    "            plt.ylabel(r'$\\frac{1}{LM}\\sum dw^2\\qquad\\qquad$     ').set_rotation(0)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.plot(t,meansqovertime, label= 'SPIN='+str(bool(self.min)))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('DATA/dataRBM_q0.1.csv', delimiter = ',')\n",
    "data = 2*data - 1\n",
    "rbm = RBM(len(data[0]),3, spin = True)\n",
    "rbm.train(data, n_epochs = 50, batch_size = 500, nplot = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "_, v_fantasy, h_fantasy = rbm.sample(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_fantasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_data = rbm.activate(data, rbm.w, rbm.b, rbm.gap)\n",
    "v_model = rbm.activate(h_data, rbm.w.T, rbm.a, 3*rbm.gap)\n",
    "v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_data = rbm.activate(data, rbm.w, rbm.b, 3*rbm.gap)\n",
    "v_model = rbm.activate(h_data, rbm.w.T, rbm.a, 3*rbm.gap)\n",
    "v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_data, v_model, h_model = rbm.sample(data)\n",
    "da, db, dw = rbm.grad(data, h_data, v_model, h_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_proportion(classes,data):\n",
    "    counts = np.zeros(len(classes)+1)\n",
    "    for datum in data:\n",
    "        # Returns len(classes) if the element did not fit any class\n",
    "        pos = next((i for i, _class in enumerate(classes) if np.array_equal(datum,_class)),len(classes))\n",
    "        counts[pos] += 1\n",
    "    percentage = counts/len(data)\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    np.array([1,1,0,0,1,1,0,0]),\n",
    "    np.array([0,0,1,1,1,1,0,0]),\n",
    "    np.array([1,1,0,0,0,0,1,1]),\n",
    "    np.array([0,0,1,1,0,0,1,1]),\n",
    "    np.array([1,1,1,1,1,1,1,1]),\n",
    "    np.array([1,0,1,0,1,0,0,0])\n",
    "]\n",
    "\n",
    "classes = np.array(classes)\n",
    "classes = 2*classes - 1\n",
    "classes = list(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_proportion(classes,v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_proportion(classes,v_fantasy[:6164]) # For some reason it breaks when we take more elements than 6164.\n",
    "# For lower temperatures, fewer sampled values fall in the last category, that of the corrupted data.\n",
    "# Notice that about as half of the values are \"corrupted\" in the v_fantasy, where beta = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Compare the convergence of the RBM parameters for the case SPINS=True and the case SPINS=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far we used the spin RBM, now we want to compare spin RBM and no-spin RBM. \n",
    "# The data saved in the file is for the no-spin RBM. To train the spin one we have to transform them applying\n",
    "# the same transfrormation done above: spin_data = 2*nospin_data:\n",
    "nospin_data = np.loadtxt('DATA/dataRBM_q0.1.csv', delimiter = ',')\n",
    "spin_data   = 2*nospin_data - 1\n",
    "\n",
    "# We create both RBM, the only distinction is the input data and the spin value\n",
    "rbm_spin   = RBM(len(spin_data[0]),3, spin = True)\n",
    "rbm_nospin = RBM(len(nospin_data[0]),3, spin = False)\n",
    "\n",
    "# Then we train them plotting only the means square increment of weights over the epochs\n",
    "plt.subplots(figsize=(12,6)) # sets the dimension\n",
    "rbm_spin.train(spin_data, n_epochs = 50, batch_size = 500, meansq = True)\n",
    "rbm_nospin.train(nospin_data, n_epochs = 50, batch_size = 500, meansq = True)\n",
    "plt.legend(prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
