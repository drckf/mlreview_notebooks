{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sgm = lambda x: 1/(1+np.exp(-x))\n",
    "nrand = np.random.random\n",
    "zerov = np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    '''A restricted Boltzmann machine model.'''\n",
    "    def __init__(self, n_variables, n_hidden, spin = False):\n",
    "        self.a = zerov(n_variables)\n",
    "        self.b = zerov(n_hidden)\n",
    "        self.w = zerov((n_hidden, n_variables))\n",
    "        self.min = -1*spin # Evaluates to zero if the model is not spin-based\n",
    "\n",
    "    def activate(self, v, w, b, gap = 1):\n",
    "        '''Turns the neurons of a forward layer on, according to a sigmoid probability function.'''\n",
    "        vec = v@w + b # The neurons evaluation\n",
    "        l = len(vec) # sample size\n",
    "        prob = sgm(gap*vec)\n",
    "        out = np.full(prob.shape,self.min)\n",
    "        out[prob < nrand(prob.shape)] = 1\n",
    "        return out\n",
    "    \n",
    "    def sample(self, v_data, steps = 1):\n",
    "        h_data = self.activate(v_data, self.w.T, self.b)\n",
    "        h_model = h_data\n",
    "        for _ in range(steps):\n",
    "            v_model = self.activate(h_model, self.w, self.a)\n",
    "            h_model = self.activate(v_model, self.w.T, self.b)\n",
    "        return h_data, v_model, h_model\n",
    "    \n",
    "    def grad(self, v_data, h_data, v_model, h_model):\n",
    "        da = np.average(v_data - v_model, axis = 0)\n",
    "        db = np.average(h_data - h_model, axis = 0)\n",
    "        dw = sum(np.outer(v_data[i],h_data[i])-np.outer(v_model[i],h_model[i]) for i in range(len(v_data)))/len(v_data)\n",
    "        #np.average(np.outer(v_data,h_data)-np.outer(v_model,h_model), axis = 1)\n",
    "        return da, db, dw\n",
    "\n",
    "    def train(self, data, n_epochs = 10, batch_size = 30, learning_rate = 1):\n",
    "        batches = len(data)//batch_size\n",
    "        for epoch in range(n_epochs):\n",
    "            np.random.shuffle(data)\n",
    "            for i in range(batches):\n",
    "                v = data[i*batch_size:(i+1)*batch_size]\n",
    "                h, v_m, h_m = self.sample(v)\n",
    "                ca, cb, cw = self.grad(v,h,v_m,h_m)\n",
    "                self.a += ca\n",
    "                self.b += cb\n",
    "                self.w += cw.T\n",
    "            learning_rate = learning_rate/(0.05*learning_rate+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-1887cda36eef>:2: RuntimeWarning: overflow encountered in exp\n  sgm = lambda x: 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('DATA/dataRBM_q0.1.csv', delimiter = ',')\n",
    "rbm = RBM(len(data[0]),4)\n",
    "rbm.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38564bit075de96200f448aeb6d0298b6117be4d",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}